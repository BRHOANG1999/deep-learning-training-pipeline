{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# üß† Welcome to Deep Learning for Neuroscience! \n",
    "\n",
    "Hello there, future computational neuroscientist! üëã\n",
    "\n",
    "Welcome to an exciting journey where cutting-edge **deep learning** meets the fascinating world of **brain science**. Whether you're here because you're curious about how neural networks can decode brain signals, or you want to build AI systems inspired by biological intelligence, you're in for a treat!\n",
    "\n",
    "## Why This Matters üéØ\n",
    "\n",
    "Think about it: your brain processes information in ways that still mystify scientists. Every time you recognize a face, remember a song, or learn something new, billions of neurons are firing in complex patterns. What if we could:\n",
    "\n",
    "- **Decode** those patterns to help paralyzed patients control robotic arms? \n",
    "- **Predict** epileptic seizures before they happen?\n",
    "- **Understand** how different brain states relate to consciousness, attention, and decision-making?\n",
    "\n",
    "That's the power of applying deep learning to neuroscience data! And the best part? You already have the CS foundation to make this happen.\n",
    "\n",
    "## What Makes This Different? ü§î\n",
    "\n",
    "Unlike traditional machine learning on images or text, neuroscience data comes with unique challenges:\n",
    "- **Time matters**: Brain signals evolve over milliseconds\n",
    "- **Noise is everywhere**: Biology is messy!\n",
    "- **Small datasets**: We can't exactly ask someone to have 10,000 seizures for our training set\n",
    "- **Interpretability is crucial**: We need to understand *why* our model works, not just *that* it works\n",
    "\n",
    "This course will teach you to navigate these challenges while building genuinely useful tools for understanding the brain.\n",
    "\n",
    "---\n",
    "\n",
    "*Ready to dive in? Let's get your environment set up first! üõ†Ô∏è*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# üó∫Ô∏è Your Learning Journey\n",
    "\n",
    "Here's the roadmap for our adventure together. Each module builds on the previous ones, but don't worry‚Äîwe'll take it step by step!\n",
    "\n",
    "## üìö Module Overview\n",
    "\n",
    "### **1. Foundation Building** üèóÔ∏è\n",
    "- **Python/NumPy Refresher**: Quick review of the tools you'll use daily\n",
    "- **Data Manipulation**: Pandas, matplotlib, and handling messy real-world data\n",
    "- **Linear Algebra in Practice**: The math behind neural networks (with code!)\n",
    "\n",
    "### **2. Machine Learning Fundamentals** ü§ñ\n",
    "- **Classical ML**: Why start with simpler models?\n",
    "- **Neural Network Basics**: Building your first network from scratch\n",
    "- **Training Deep Networks**: Backpropagation, optimizers, and avoiding common pitfalls\n",
    "\n",
    "### **3. Introduction to Neuroscience Data** üß¨\n",
    "- **EEG Basics**: What are we actually measuring?\n",
    "- **Signal Processing**: Filtering, artifacts, and cleaning noisy brain data\n",
    "- **MNE Python**: The Swiss Army knife for neurophysiology data\n",
    "\n",
    "### **4. PyTorch for Neuroscience** üî•\n",
    "- **Tensor Operations**: Working efficiently with multidimensional brain data\n",
    "- **Custom Datasets**: Handling time series and irregular sampling\n",
    "- **GPU Acceleration**: Making your code lightning fast\n",
    "\n",
    "### **5. Advanced Architectures** üèõÔ∏è\n",
    "- **Sequence Modeling**: RNNs, LSTMs, and Transformers for time series\n",
    "- **Convolutional Networks**: Spatial patterns in neural data\n",
    "- **Attention Mechanisms**: What parts of the signal matter most?\n",
    "\n",
    "### **6. Real-World Applications** üåç\n",
    "- **Brain-Computer Interfaces**: Decoding movement intentions\n",
    "- **Clinical Applications**: Seizure detection and sleep staging\n",
    "- **Research Projects**: Design your own neuroscience experiment\n",
    "\n",
    "---\n",
    "\n",
    "**Estimated Timeline**: ~8-10 weeks if you dedicate 4-6 hours per week  \n",
    "**Prerequisites**: Basic Python programming, introductory statistics  \n",
    "**Outcome**: You'll build a complete brain signal classifier from scratch!\n",
    "\n",
    "*Sound exciting? Let's make sure your computer is ready for this journey! üíª*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# ‚öôÔ∏è Environment Setup\n",
    "\n",
    "## üåê Are you using Google Colab?\n",
    "\n",
    "Good choice! Colab is perfect for this course because it gives you free access to GPUs and comes with many packages pre-installed.\n",
    "\n",
    "### üöÄ **IMPORTANT: Switch to GPU Runtime!**\n",
    "\n",
    "Neural networks train much faster on GPUs. Here's how to enable it:\n",
    "\n",
    "1. Click **Runtime** ‚Üí **Change runtime type**\n",
    "2. Set **Hardware accelerator** to **GPU** (T4 or better if available)\n",
    "3. Click **Save**\n",
    "4. If prompted to restart, click **Restart Runtime**\n",
    "\n",
    "**Why does this matter?** Training a neural network on CPU might take 30 minutes, while the same task on GPU finishes in 2-3 minutes. Trust us, your patience will thank you! ‚ö°\n",
    "\n",
    "### üíª Local Development?\n",
    "\n",
    "If you're running this locally, make sure you have:\n",
    "- **Python 3.8+** (3.9 or 3.10 recommended)\n",
    "- **Jupyter Lab** or **Jupyter Notebook**\n",
    "- **CUDA** drivers if you have an NVIDIA GPU\n",
    "\n",
    "*Don't worry if some of this sounds foreign‚Äîwe'll check everything in the next sections!*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# üì¶ Installing Required Packages\n",
    "\n",
    "Time to install our toolkit! We'll install packages in groups so you understand what each one does.\n",
    "\n",
    "**‚è±Ô∏è This might take 2-3 minutes.** Perfect time to grab some coffee or tea! ‚òï\n",
    "\n",
    "## Core Scientific Computing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Essential scientific computing libraries\n# These are the backbone of data science in Python!\n\nimport sys\nimport subprocess\nimport importlib.util\n\ndef install_with_progress(package_name, display_name=None):\n    \"\"\"Install package with progress feedback and error handling\"\"\"\n    if display_name is None:\n        display_name = package_name\n    \n    try:\n        print(f\"üîÑ Installing {display_name}...\")\n        result = subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", package_name], \n                              capture_output=True, text=True, timeout=300)\n        \n        if result.returncode == 0:\n            print(f\"‚úÖ {display_name} installed successfully!\")\n            return True\n        else:\n            print(f\"‚ùå Error installing {display_name}: {result.stderr}\")\n            return False\n            \n    except subprocess.TimeoutExpired:\n        print(f\"‚è∞ Installation of {display_name} timed out. Please try again.\")\n        return False\n    except Exception as e:\n        print(f\"‚ùå Unexpected error installing {display_name}: {e}\")\n        return False\n\ndef check_package_installed(package_name):\n    \"\"\"Check if a package is already installed\"\"\"\n    return importlib.util.find_spec(package_name) is not None\n\n# Core packages with smart installation\npackages = [\n    (\"numpy\", \"NumPy: Fast numerical computing\"),\n    (\"pandas\", \"Pandas: Data manipulation and analysis\"),\n    (\"matplotlib\", \"Matplotlib: Plotting and visualization\"),\n    (\"scipy\", \"SciPy: Scientific computing tools\")\n]\n\nprint(\"üì¶ Installing Core Scientific Computing Packages...\")\nprint(\"=\" * 50)\n\ninstallation_results = {}\nfor package, description in packages:\n    if check_package_installed(package):\n        print(f\"‚úÖ {package} already installed!\")\n        installation_results[package] = True\n    else:\n        installation_results[package] = install_with_progress(package)\n\nprint(\"\\nüìä Installation Summary:\")\nfor package, success in installation_results.items():\n    status = \"‚úÖ\" if success else \"‚ùå\"\n    print(f\"   {status} {package}\")\n\n# Test imports\nprint(\"\\nüß™ Testing imports...\")\ntry:\n    import numpy as np\n    import pandas as pd\n    import matplotlib.pyplot as plt\n    import scipy\n    print(\"‚úÖ All core packages imported successfully!\")\nexcept ImportError as e:\n    print(f\"‚ùå Import error: {e}\")\n    print(\"üí° Try restarting your kernel and running this cell again.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Machine Learning & Deep Learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine learning libraries\n",
    "# scikit-learn: Traditional ML algorithms and preprocessing\n",
    "# torch: PyTorch for deep learning (the star of our show!)\n",
    "\n",
    "%pip install scikit-learn torch torchvision\n",
    "\n",
    "print(\"‚úÖ Machine Learning packages installed!\")\n",
    "print(\"   üß† Scikit-learn: Traditional ML algorithms\")\n",
    "print(\"   üî• PyTorch: Deep learning framework\")  \n",
    "print(\"   üëÅÔ∏è  Torchvision: Computer vision utilities\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Neuroscience-Specific Tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNE-Python: The Swiss Army knife for neurophysiology data\n",
    "# This is THE library for working with EEG, MEG, and other brain signals\n",
    "\n",
    "%pip install mne\n",
    "\n",
    "print(\"‚úÖ Neuroscience packages installed!\")\n",
    "print(\"   üß¨ MNE-Python: EEG/MEG/neurophysiology data analysis\")\n",
    "print(\"   üì° Handles file formats, filtering, artifact removal, and much more!\")\n",
    "\n",
    "# Note: MNE comes with sample datasets we'll use throughout the course!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# üß™ Testing Your Installation\n",
    "\n",
    "Let's make sure everything is working! Run the cell below to import all packages and check their versions.\n",
    "\n",
    "**If you see any errors**, don't panic! Just re-run the installation cells above and try again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import sys\nimport platform\nimport psutil\nimport warnings\nwarnings.filterwarnings('ignore')\n\nprint(f\"üêç Python version: {sys.version}\")\nprint(f\"üíª Platform: {platform.system()} {platform.release()}\")\nprint(f\"üîß Architecture: {platform.machine()}\")\nprint(\"-\" * 60)\n\n# Enhanced system information\ntry:\n    memory_info = psutil.virtual_memory()\n    print(f\"üíæ Total RAM: {memory_info.total / (1024**3):.1f} GB\")\n    print(f\"üíæ Available RAM: {memory_info.available / (1024**3):.1f} GB\")\n    print(f\"üíæ RAM Usage: {memory_info.percent}%\")\n    \n    cpu_count = psutil.cpu_count()\n    print(f\"üî• CPU Cores: {cpu_count}\")\n    \nexcept Exception as e:\n    print(f\"‚ÑπÔ∏è System info partially available: {e}\")\n\nprint(\"-\" * 60)\n\n# Package version checking with error handling\npackage_versions = {}\npackages_to_check = [\n    ('numpy', 'NumPy'),\n    ('pandas', 'Pandas'),\n    ('matplotlib', 'Matplotlib'),\n    ('scipy', 'SciPy'),\n    ('sklearn', 'Scikit-learn'),\n    ('torch', 'PyTorch'),\n    ('torchvision', 'Torchvision'),\n    ('mne', 'MNE-Python')\n]\n\nprint(\"üì¶ Package Versions:\")\nfor package, display_name in packages_to_check:\n    try:\n        module = __import__(package)\n        version = getattr(module, '__version__', 'Unknown')\n        package_versions[package] = version\n        print(f\"   üìä {display_name}: {version}\")\n    except ImportError:\n        print(f\"   ‚ùå {display_name}: Not installed\")\n        package_versions[package] = None\n    except Exception as e:\n        print(f\"   ‚ö†Ô∏è {display_name}: Error checking version - {e}\")\n        package_versions[package] = None\n\nprint(\"-\" * 60)\n\n# GPU Detection with detailed information\ngpu_available = False\ngpu_info = \"None detected\"\n\ntry:\n    import torch\n    if torch.cuda.is_available():\n        gpu_available = True\n        gpu_count = torch.cuda.device_count()\n        gpu_name = torch.cuda.get_device_name(0)\n        gpu_memory = torch.cuda.get_device_properties(0).total_memory\n        gpu_info = f\"{gpu_name} ({gpu_memory / 1e9:.1f} GB)\"\n        \n        print(f\"üöÄ GPU Status: {gpu_count} GPU(s) available\")\n        print(f\"üöÄ Primary GPU: {gpu_info}\")\n        print(f\"üöÄ CUDA Version: {torch.version.cuda}\")\n        \n        # Memory usage\n        if gpu_count > 0:\n            memory_allocated = torch.cuda.memory_allocated(0) / 1e9\n            memory_reserved = torch.cuda.memory_reserved(0) / 1e9\n            print(f\"üöÄ GPU Memory: {memory_allocated:.2f} GB allocated, {memory_reserved:.2f} GB reserved\")\n    else:\n        print(\"üíª GPU Status: No CUDA GPUs available\")\n        print(\"üí° For faster training, consider using Google Colab with GPU runtime\")\n        \nexcept ImportError:\n    print(\"‚ùå PyTorch not installed - GPU detection unavailable\")\nexcept Exception as e:\n    print(f\"‚ö†Ô∏è GPU detection error: {e}\")\n\nprint(\"-\" * 60)\n\n# Environment recommendations\nprint(\"üéØ Environment Assessment:\")\n\n# Check for Jupyter environment\ntry:\n    from IPython import get_ipython\n    if get_ipython() is not None:\n        print(\"‚úÖ Running in Jupyter environment\")\n        \n        # Check if in Colab\n        try:\n            import google.colab\n            print(\"‚úÖ Google Colab detected - GPU runtime recommended\")\n        except ImportError:\n            print(\"‚ÑπÔ∏è Local Jupyter environment detected\")\n    else:\n        print(\"‚ÑπÔ∏è Not running in Jupyter environment\")\nexcept Exception:\n    print(\"‚ÑπÔ∏è Environment detection unavailable\")\n\n# Performance recommendations\nmissing_packages = [name for name, version in package_versions.items() if version is None]\nif missing_packages:\n    print(f\"‚ö†Ô∏è Missing packages: {', '.join(missing_packages)}\")\n    print(\"üí° Install missing packages for full functionality\")\n\nif not gpu_available:\n    print(\"üí° Consider enabling GPU for faster neural network training\")\n\nprint(f\"\\nüéâ Setup Status: {'‚úÖ READY' if len(missing_packages) == 0 else '‚ö†Ô∏è NEEDS ATTENTION'}\")\nprint(\"üöÄ You're ready to start your deep learning journey!\")\n\n# Save environment info for troubleshooting\nenv_info = {\n    'python_version': sys.version,\n    'platform': platform.system(),\n    'packages': package_versions,\n    'gpu_available': gpu_available,\n    'gpu_info': gpu_info\n}\n\nprint(\"\\nüíæ Environment info saved for troubleshooting\")\nprint(\"   (Access via 'env_info' variable in subsequent cells)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": "# üî¨ Interactive Neural Signal Exploration\n\nNow let's dive into something really exciting! We'll create an interactive tool to explore different types of brain waves. This will help you understand the fundamental rhythms of neural activity that we'll be working with throughout the course.",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom IPython.display import display, HTML, clear_output\n\n# Try to import interactive widgets\ntry:\n    import ipywidgets as widgets\n    from ipywidgets import interact, interactive, fixed, interact_manual\n    WIDGETS_AVAILABLE = True\nexcept ImportError:\n    WIDGETS_AVAILABLE = False\n\n# Set up matplotlib for interactive plots\nplt.rcParams['figure.figsize'] = (12, 6)\nplt.rcParams['font.size'] = 10\n\ndef generate_brain_signal(signal_type='alpha', amplitude=2, noise_level=0.5, duration=2):\n    \"\"\"Generate different types of brain signals with physiologically correct frequencies\"\"\"\n    \n    # Time axis\n    sampling_rate = 250  # Hz\n    time_points = np.linspace(0, duration, int(sampling_rate * duration))\n    \n    # Define physiologically correct frequency ranges for each signal type\n    if signal_type == 'alpha':\n        # Alpha waves (8-13 Hz) - use 10 Hz as typical\n        frequency = 10\n        signal = amplitude * np.sin(2 * np.pi * frequency * time_points)\n        description = \"Alpha waves: 8-13 Hz, relaxed/meditative states\"\n        color = 'blue'\n    elif signal_type == 'beta':\n        # Beta waves (13-30 Hz) - use 20 Hz as typical\n        frequency = 20\n        signal = amplitude * np.sin(2 * np.pi * frequency * time_points)\n        description = \"Beta waves: 13-30 Hz, active concentration\"\n        color = 'red'\n    elif signal_type == 'theta':\n        # Theta waves (4-8 Hz) - use 6 Hz as typical\n        frequency = 6\n        signal = amplitude * np.sin(2 * np.pi * frequency * time_points)\n        description = \"Theta waves: 4-8 Hz, creativity/deep meditation\"\n        color = 'green'\n    elif signal_type == 'delta':\n        # Delta waves (0.5-4 Hz) - use 2 Hz as typical\n        frequency = 2\n        signal = amplitude * np.sin(2 * np.pi * frequency * time_points)\n        description = \"Delta waves: 0.5-4 Hz, deep sleep\"\n        color = 'purple'\n    elif signal_type == 'gamma':\n        # Gamma waves (30-100 Hz) - use 40 Hz as typical\n        frequency = 40\n        signal = amplitude * np.sin(2 * np.pi * frequency * time_points)\n        description = \"Gamma waves: 30-100 Hz, high-level cognition\"\n        color = 'orange'\n    else:\n        # Mixed signal - realistic combination\n        signal = (amplitude * 0.6 * np.sin(2 * np.pi * 10 * time_points) +    # Alpha (dominant)\n                 amplitude * 0.3 * np.sin(2 * np.pi * 20 * time_points) +    # Beta\n                 amplitude * 0.4 * np.sin(2 * np.pi * 6 * time_points) +     # Theta\n                 amplitude * 0.2 * np.sin(2 * np.pi * 2 * time_points))      # Delta\n        description = \"Mixed signal: Realistic brain activity (multiple rhythms)\"\n        color = 'black'\n        frequency = 'Mixed (2-40 Hz)'\n    \n    # Add realistic noise\n    noise = noise_level * np.random.randn(len(time_points))\n    signal_with_noise = signal + noise\n    \n    return time_points, signal_with_noise, description, color, frequency\n\ndef plot_brain_signal(signal_type='alpha', amplitude=2, noise_level=0.5):\n    \"\"\"Interactive plotting function\"\"\"\n    \n    # Generate signal\n    time_points, signal, description, color, frequency = generate_brain_signal(\n        signal_type, amplitude, noise_level\n    )\n    \n    # Create figure\n    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n    \n    # Time domain plot\n    ax1.plot(time_points, signal, color=color, linewidth=2, alpha=0.8)\n    ax1.set_xlabel('Time (seconds)')\n    ax1.set_ylabel('Amplitude (ŒºV)')\n    ax1.set_title(f'{signal_type.title()} Wave Signal - {description}')\n    ax1.grid(True, alpha=0.3)\n    ax1.set_xlim(0, 2)\n    \n    # Frequency domain plot\n    from scipy.signal import welch\n    frequencies, power = welch(signal, fs=250, nperseg=512)\n    \n    ax2.semilogy(frequencies, power, color=color, linewidth=2, alpha=0.8)\n    ax2.set_xlabel('Frequency (Hz)')\n    ax2.set_ylabel('Power Spectral Density')\n    ax2.set_title('Frequency Spectrum')\n    ax2.grid(True, alpha=0.3)\n    ax2.set_xlim(0, 50)\n    \n    # Add frequency band markers with labels\n    bands = [\n        ('Delta', (0.5, 4), 'lightblue'),\n        ('Theta', (4, 8), 'lightgreen'), \n        ('Alpha', (8, 13), 'lightcoral'),\n        ('Beta', (13, 30), 'lightyellow'),\n        ('Gamma', (30, 50), 'lightpink')\n    ]\n    \n    for band, (low, high), band_color in bands:\n        ax2.axvspan(low, high, alpha=0.2, color=band_color, label=f'{band} ({low}-{high} Hz)')\n    \n    ax2.legend(loc='upper right', fontsize=8)\n    \n    plt.tight_layout()\n    plt.show()\n    \n    # Analysis\n    dominant_freq = frequencies[np.argmax(power)]\n    print(f\"\\nüìä Signal Analysis:\")\n    print(f\"   üéØ Signal frequency: {frequency} Hz\")\n    print(f\"   üéØ Dominant frequency in PSD: {dominant_freq:.1f} Hz\")\n    print(f\"   üìè Signal amplitude: {amplitude:.1f} ŒºV\")\n    print(f\"   üîä Noise level: {noise_level:.1f}\")\n    print(f\"   üìà Signal-to-noise ratio: {amplitude/noise_level:.1f}\")\n    \n    # Clinical interpretation based on actual frequency\n    if signal_type == 'alpha' and 8 <= dominant_freq <= 13:\n        print(f\"   üè• Clinical note: Normal alpha rhythm detected\")\n    elif signal_type == 'beta' and 13 <= dominant_freq <= 30:\n        print(f\"   üè• Clinical note: Normal beta activity detected\")\n    elif signal_type == 'theta' and 4 <= dominant_freq <= 8:\n        print(f\"   üè• Clinical note: Normal theta rhythm detected\")\n    elif signal_type == 'delta' and 0.5 <= dominant_freq <= 4:\n        print(f\"   üè• Clinical note: Normal delta rhythm detected\")\n    elif signal_type == 'gamma' and 30 <= dominant_freq <= 100:\n        print(f\"   üè• Clinical note: Normal gamma activity detected\")\n    elif noise_level > amplitude:\n        print(f\"   ‚ö†Ô∏è Clinical note: High noise level may require preprocessing\")\n\nprint(\"üß† Interactive Brain Signal Explorer\")\nprint(\"=\" * 50)\nprint(\"Explore different types of brain waves and their characteristics!\")\nprint(\"üéØ Learning objectives:\")\nprint(\"   ‚Ä¢ Understand different brain wave frequencies\")\nprint(\"   ‚Ä¢ Observe signal-to-noise ratios\")\nprint(\"   ‚Ä¢ Connect brain states to electrical activity\")\nprint(\"   ‚Ä¢ Learn frequency domain analysis\")\n\n# Create interactive widget (removed frequency slider)\nif WIDGETS_AVAILABLE:\n    try:\n        # Interactive controls\n        signal_widget = widgets.Dropdown(\n            options=['alpha', 'beta', 'theta', 'delta', 'gamma', 'mixed'],\n            value='alpha',\n            description='Signal Type:'\n        )\n        \n        amplitude_widget = widgets.FloatSlider(\n            value=2,\n            min=0.5,\n            max=5,\n            step=0.1,\n            description='Amplitude (ŒºV):'\n        )\n        \n        noise_widget = widgets.FloatSlider(\n            value=0.5,\n            min=0,\n            max=2,\n            step=0.1,\n            description='Noise Level:'\n        )\n        \n        # Create interactive plot (no frequency parameter)\n        interactive_plot = interactive(plot_brain_signal, \n                                     signal_type=signal_widget,\n                                     amplitude=amplitude_widget,\n                                     noise_level=noise_widget)\n        \n        display(interactive_plot)\n        \n    except Exception as e:\n        print(f\"‚ö†Ô∏è Interactive widgets error: {e}\")\n        print(\"üí° Showing static example instead...\")\n        plot_brain_signal('alpha', 2, 0.5)\nelse:\n    print(\"‚ö†Ô∏è Interactive widgets not available (ipywidgets not installed)\")\n    print(\"üí° You can still explore signals by running the function manually:\")\n    print(\"   plot_brain_signal('alpha', amplitude=2, noise_level=0.5)\")\n    \n    # Show a default example\n    plot_brain_signal('alpha', 2, 0.5)\n\nprint(\"\\nüéØ Try This:\")\nprint(\"   1. Change signal type to see correct frequency bands\")\nprint(\"   2. Notice how PSD peaks align with physiological ranges\")\nprint(\"   3. Increase noise level to see preprocessing challenges\")\nprint(\"   4. Compare mixed signals to single-frequency waves\")\n\nprint(\"\\nüè• Clinical Applications:\")\nprint(\"   ‚Ä¢ EEG analysis for sleep studies\")\nprint(\"   ‚Ä¢ Seizure detection algorithms\")\nprint(\"   ‚Ä¢ Brain-computer interface development\")\nprint(\"   ‚Ä¢ Neurofeedback therapy systems\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}